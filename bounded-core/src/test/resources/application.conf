
akka {
  loglevel = DEBUG
  loglevel = ${?AKKA_LOGLEVEL}
  loggers = ["akka.event.slf4j.Slf4jLogger"]

  statsd {
    hostname = "graphite.thenewmotion.org"
    port = 8125
    namespace = "bounded.test.v2g-service"
    namespace = ${?STATSD_NAMESPACE}
  }

  actor {
    provider = "akka.actor.LocalActorRefProvider"

    serializers {
      serializer = "v2g.smartdriver.persistence.SmartDriverPersistersSerializer"
      //      serializer2 = "v2g.aggregator.nuvve.persistance.NuvvePersistersSerializer"
    }
    serialization-bindings {
      "stamina.Persistable" = serializer
      // enable below to check if all events have been serialized without java.io.Serializable
      //"java.io.Serializable" = none
      //      "AggregatorDomainEvent" = serializer2
    }
  }

  persistence {
    journal {
      # plugin = "akka.persistence.journal.leveldb"
      plugin = "cassandra-journal"
    }
  }

  snapshot-store.local.dir = "snapshots"
}

nuvve-aggregator-blocking-dispatcher {
  type = Dispatcher
  executor = "thread-pool-executor"
  thread-pool-executor {
    fixed-pool-size = 16
  }
  throughput = 1
}

cassandra-journal {
  event-adapters {
    tagging = "v2g.smartdriver.persistence.SmartDriverTaggingEventAdapter"
  }

  event-adapter-bindings {
    "v2g.smartdriver.domain.SmartDriverDomainProtocol$SmartDriverDomainEvent" = tagging
  }

  # FQCN of the cassandra journal plugin
  class = "akka.persistence.cassandra.journal.CassandraJournal"

  contactpoint = "localhost"
  contactpoint = ${?V2G_CASSANDRA_HOST}
  # Comma-separated list of contact points in the Cassandra cluster.
  # Host:Port pairs are also supported. In that case the port parameter will be ignored.
  contact-points = [${cassandra-journal.contactpoint}]

  # Port of contact points in the Cassandra cluster.
  # Will be ignored if the contact point list is defined by host:port pairs.
  port = 9042
  port = ${?V2G_CASSANDRA_PORT}

  # The implementation of akka.persistence.cassandra.SessionProvider
  # is used for creating the Cassandra Session. By default the
  # the ConfigSessionProvider is building the Cluster from configuration properties
  # but it is possible to replace the implementation of the SessionProvider
  # to reuse another session or override the Cluster builder with other
  # settings.
  # For example, it is possible to lookup the contact points of the Cassandra cluster
  # asynchronously instead of giving them in the configuration in a subclass of
  # ConfigSessionProvider and overriding the lookupContactPoints method.
  # It may optionally have a constructor with an ActorSystem and Config parameter.
  # The config parameter is this config section of the plugin.
  session-provider = akka.persistence.cassandra.ConfigSessionProvider

  # The identifier that will be passed as parameter to the
  # ConfigSessionProvider.lookupContactPoints method.
  cluster-id = ""

  # Name of the keyspace to be created/used by the journal
  keyspace = "akka"

  # Parameter indicating whether the journal keyspace should be auto created
  keyspace-autocreate = true

  # Parameter indicating whether the journal tables should be auto created
  tables-autocreate = true

  # The number of retries when a write request returns a TimeoutException or an UnavailableException.
  write-retries = 3

  # Deletes are achieved using a metadata entry and then the actual messages are deleted asynchronously
  # Number of retries before giving up
  delete-retries = 3

  # Number of retries before giving up connecting for the initial connection to the Cassandra cluster
  connect-retries = 3

  # Delay between connection retries, for the initial connection to the Cassandra cluster
  connect-retry-delay = 1s

  # Max delay of the ExponentialReconnectionPolicy that is used when reconnecting
  # to the Cassandra cluster
  reconnect-max-delay = 30s

  # Cassandra driver connection pool settings
  # Documented at https://datastax.github.io/java-driver/manual/pooling/
  connection-pool {

    # Create new connection threshold local
    new-connection-threshold-local = 800

    # Create new connection threshold remote
    new-connection-threshold-remote = 200

    # Connections per host core local
    connections-per-host-core-local = 1

    # Connections per host max local
    connections-per-host-max-local = 4

    # Connections per host core remote
    connections-per-host-core-remote = 1

    # Connections per host max remote
    connections-per-host-max-remote = 4

    # Max requests per connection local
    max-requests-per-connection-local = 32768

    # Max requests per connection remote
    max-requests-per-connection-remote = 2000

    # Sets the timeout when trying to acquire a connection from a host's pool
    pool-timeout-millis = 0
  }

  # Name of the table to be created/used by the journal.
  # If the table doesn't exist it is automatically created.
  table = "messages"

  # Compaction strategy for the journal table.
  # Please refer to the tests for example configurations.
  # Refer to http://docs.datastax.com/en/cql/3.1/cql/cql_reference/compactSubprop.html
  # for more information regarding the properties.
  table-compaction-strategy {
    class = "SizeTieredCompactionStrategy"
  }

  # Name of the table to be created/used for storing metadata.
  # If the table doesn't exist it is automatically created.
  metadata-table = "metadata"

  # Name of the table to be created/used for journal config.
  # If the table doesn't exist it is automatically created.
  config-table = "config"

  # Set this to on to only use Cassandra 2.x compatible features,
  # i.e. if you are using a Cassandra 2.x server.
  # To run tests with Cassandra 2.x server you have to do the following:
  # - start Cassandra 2.x server on default port 9042, with empty data directory
  # - change CassandraLauncher.randomPort to 9042
  # - change CassandraLauncher.start to do nothing
  # - set this cassandra-2x-compat = on
  # - note that you must delete all data between each bounded.test run
  cassandra-2x-compat = off

  # Possibility to disable the eventsByTag query and creation of
  # the materialized view. This will automatically be off when
  # cassandra-2x-compat=on
  enable-events-by-tag-query = on

  # Name of the materialized view for eventsByTag query
  events-by-tag-view = "eventsbytag"

  # replication strategy to use. SimpleStrategy or NetworkTopologyStrategy
  replication-strategy = "SimpleStrategy"

  # Replication factor to use when creating a keyspace. Is only used when replication-strategy is SimpleStrategy.
  replication-factor = 1

  # Replication factor list for data centers, e.g. ["dc1:3", "dc2:2"]. Is only used when replication-strategy is NetworkTopologyStrategy.
  data-center-replication-factors = []

  # To limit the Cassandra hosts this plugin connects with to a specific datacenter.
  # (DCAwareRoundRobinPolicy withLocalDc)
  # The id for the local datacenter of the Cassandra hosts it should connect to.
  # By default, this property is not set resulting in Datastax's standard round robin policy being used.
  local-datacenter = ""

  # Number of hosts from non-local datacenter to use as a fall-back policy.
  # Works only when local-datacenter is set
  used-hosts-per-remote-dc = 0

  # To connect to the Cassandra hosts with credentials.
  # Authentication is disabled if username is not configured.
  authentication.username = ""
  authentication.password = ""

  # SSL can be configured with the following properties.
  # SSL is disabled if the truststore is not configured.
  # For detailed instructions, please refer to the DataStax Cassandra chapter about
  # SSL Encryption: http://docs.datastax.com/en/cassandra/2.0/cassandra/security/secureSslEncryptionTOC.html
  # Path to the JKS Truststore file
  ssl.truststore.path = ""
  # Password to unlock the JKS Truststore
  ssl.truststore.password = ""
  # Path to the JKS Keystore file (optional config, only needed for client authentication)
  ssl.keystore.path = ""
  # Password to unlock JKS Truststore and access the private key (both must use the same password)
  ssl.keystore.password = ""

  # Write consistency level
  # The default read and write consistency levels ensure that persistent actors can read their own writes.
  # During normal operation, persistent actors only write to the journal, reads occur only during recovery.
  write-consistency = "QUORUM"

  # Read consistency level
  read-consistency = "QUORUM"

  # Maximum number of messages that will be batched when using `persistAsync`.
  # Also used as the max batch size for deletes.
  max-message-batch-size = 100

  # Target number of entries per partition (= columns per row).
  # Must not be changed after table creation (currently not checked).
  # This is "target" as AtomicWrites that span partition boundaries will result in bigger partitions to ensure atomicity.
  target-partition-size = 500000

  # Maximum size of result set
  max-result-size = 50001

  # Maximum size of result set during replay
  max-result-size-replay = 50001

  # The query journal to use when recoverying
  query-plugin = "cassandra-query-journal"

  # Dispatcher for the plugin actor.
  plugin-dispatcher = "cassandra-plugin-default-dispatcher"

  # Dispatcher for potentially blocking tasks.
  blocking-dispatcher = "cassandra-plugin-blocking-dispatcher"

  # The time to wait before cassandra will remove the thombstones created for deleted entries.
  # cfr. gc_grace_seconds table property documentation on http://www.datastax.com/documentation/cql/3.1/cql/cql_reference/tabProp.html
  gc-grace-seconds = 864000

  # When using more than one tag per event you have to configure know
  # tags in this section to give each tag an identifier. When using
  # only one tag per event the identifier is 1, automatically.
  # tagname = tagid
  # where tagid must be 1, 2, or 3. Max 3 tags per event is supported.
  # For example:
  #   BlogPosts = 1
  #   Announcement = 2
  #   Authors = 1
  # With those tag identifiers you can use BlogPosts and Announcement for a single event,
  # but you cannot combine BlogPosts and Authors, since they have the same tag identifier.
  tags {
  }

  # Minimum time between publishing messages to DistributedPubSub to announce events for a specific tag have
  # been written. These announcements cause any ongoing getEventsByTag to immediately re-poll, rather than
  # wait. In order enable this feature, make the following settings:
  #
  #    - enable clustering for your actor system
  #    - cassandra-journal.pubsub-minimum-interval = 1s              (send real-time announcements at most every sec)
  #    - cassandra-query-journal.eventual-consistency-delay = 0s     (so it immediately tries to show changes)
  #
  # Setting pubsub-minimum-interval to "off" will disable the journal sending these announcements.
  pubsub-minimum-interval = off

  # Set the protocol version explicitly, should only be used for compatibility testing.
  # Supported values: 3, 4
  protocol-version = ""
}

# Configuration for the CassandraReadJournal
cassandra-query-journal {
  # Implementation class of the Cassandra ReadJournalProvider
  class = "akka.persistence.cassandra.query.CassandraReadJournalProvider"

  # Absolute path to the write journal plugin configuration section
  write-plugin = "cassandra-journal"

  # New events are retrieved (polled) with this interval.
  refresh-interval = 1s

  # How many events to fetch in one query (replay) and keep buffered until they
  # are delivered downstreams.
  max-buffer-size = 500

  # The fetch size of the Cassandra select statement
  # Value less or equal to 0 means max-result-size will be used
  # http://docs.datastax.com/en/drivers/java/3.0/com/datastax/driver/core/Statement.html
  max-result-size-query = 250

  # Read consistency level
  read-consistency = "QUORUM"

  # Configure this to the day (yyyyMMdd) when the system was first started.
  # When offset 0L is used it will look for events from this day and forward.
  first-time-bucket = "20170718"

  # The returned event stream is ordered by the offset (timestamp), which corresponds
  # to the same order as the write journal stored the events, with inaccuracy due to clock skew
  # between different nodes. The same stream elements (in same order) are returned for multiple
  # executions of the query on a best effort basis. The query is using a Cassandra Materialized
  # View for the query and that is eventually consistent, so different queries may see different
  # events for the latest events, but eventually the result will be ordered by timestamp
  # (Cassandra timeuuid column). To compensate for the the eventual consistency the query is
  # delayed to not read the latest events, the duration of this delay is defined by this
  # configuration property.
  # However, this is only best effort and in case of network partitions
  # or other things that may delay the updates of the Materialized View the events may be
  # delivered in different order (not strictly by their timestamp)
  eventual-consistency-delay = 1s

  # For each `persistenceId` the events are delivered strictly by sequence number. If
  # a sequence number is missing the query is delayed up to the configured
  # `delayed-event-timeout` and if the expected event is still not found
  # the stream is completed with failure.
  delayed-event-timeout = 3s

  # Dispatcher for the plugin actors.
  plugin-dispatcher = "akka.actor.default-dispatcher"
}

akka {
  loglevel = "DEBUG"
  stdout-loglevel = "DEBUG"
  loggers = ["akka.testkit.TestEventListener"]
  actor {
    default-dispatcher {
      executor = "fork-join-executor"
      fork-join-executor {
        parallelism-min = 8
        parallelism-factor = 2.0
        parallelism-max = 8
      }
    }
    serialize-creators = off
    serialize-messages = off
    serializers {
//      serializer = "v2g.smartdriver.persistence.SmartDriverPersistersSerializer",
      serializer = "v2g.aggregator.nuvve.persistance.NuvvePersistersSerializer"
    }
    serialization-bindings {
      "stamina.Persistable" = serializer
      // enable below to check if all events have been serialized without java.io.Serializable
      "java.io.Serializable" = none
    }
  }
  persistence {
    publish-confirmations = on
    publish-plugin-commands = on
    journal {
      plugin = "inmemory-journal"
      inmemory-journal {
        event-adapters {
          tagging = "v2g.smartdriver.persistence.SmartDriverTaggingEventAdapter"
        }
        event-adapter-bindings {
          "v2g.smartdriver.domain.SmartDriverDomainProtocol$SmartDriverDomainEvent" = tagging
        }
      }
    }
  }
  bounded.test {
    single-expect-default = 10s
    timefactor = 1
  }

}